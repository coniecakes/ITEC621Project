---
title: "ITEC 621 Project"
author: 
  - name: "Ledia Dobi"
    affiliation: "American University"
    email: "ld5469a@american.edu"
  - name: "Conie O'Malley"
    affiliation: "American University"
    email: "co1984a@american.edu"
date: "`r Sys.Date()`"
format: 
  html:
    theme: cosmo # Use a Bootswatch theme for consistent styling
    highlight-style: github # Syntax highlighting style
    toc: true
    toc-depth: 4
    number-sections: true # Number the heading sections
    embed-resources: true
    fig-width: 6 # Default figure width in inches
    fig-height: 4 # Default figure height in inches
    df-print: paged
#    css: styles.css # Custom styling
#    include-after-body: footer.html # Custom footer
---

```{r libraries}
# library chunk
#install.packages("dplyr")
#install.packages("readr")
#install.packages("tidyverse")
library(dplyr)
library(readr)
library(tidyverse)
library(lmtest)
```

```{r data import}
# import data sets
median_sale_price <- readr::read_csv("data/Metro_median_sale_price_uc_sfr_month.csv")
new_construction_sales <- readr::read_csv("data/Metro_new_con_sales_count_raw_uc_sfr_month.csv")
mean_sfr_value <- readr::read_csv("data/Metro_zhvi_uc_sfr_tier_0.33_0.67_sm_sa_month.csv")
```

```{r data cleaning}
# remove columns and pivot longer
ny_median_sale_price <- median_sale_price %>% 
  dplyr::filter(RegionName == "New York, NY") %>% 
  dplyr::select(-RegionID, -SizeRank, -RegionType, -StateName) %>% 
  tidyr::pivot_longer(cols = -RegionName,
    names_to = "Date",
    values_to = "median_sale_price"
  )

ny_new_construction_sales <- new_construction_sales %>% 
  dplyr::filter(RegionName == "New York, NY") %>% 
  dplyr::select(-RegionID, -SizeRank, -RegionType, -StateName) %>% 
  tidyr::pivot_longer(cols = -RegionName,
    names_to = "Date",
    values_to = "new_construction_sales"
  ) %>% 
    dplyr::select(-RegionName)

ny_mean_sfr_value <- mean_sfr_value %>% 
  dplyr::filter(RegionName == "New York, NY") %>% 
  dplyr::select(-RegionID, -SizeRank, -RegionType, -StateName) %>% 
  tidyr::pivot_longer(cols = -RegionName,
    names_to = "Date",
    values_to = "mean_sfr_value"
  ) %>% 
    dplyr::select(-RegionName)

# join data sets
ny_housing_data <- ny_median_sale_price %>% 
  dplyr::left_join(ny_new_construction_sales, by = "Date") %>% 
  dplyr::left_join(ny_mean_sfr_value, by = "Date")

# Convert Date from character to Date class
ny_housing_data$Date <- as.Date(ny_housing_data$Date)

# get rid of NA values
ny_housing_data_clean <- na.omit(ny_housing_data)
```


```{r descriptive_analytics}

#qqplot and histogram for residuals
options(scipen=4)
lm.fit <- lm(median_sale_price ~ Date + new_construction_sales + mean_sfr_value, 
             data = ny_housing_data_clean)
par(mar=c(4,4,2,2))
plot(lm.fit, which = 2)
hist(lm.fit$residuals)

#heteroskedasticity check
plot(lm.fit$residuals ~ lm.fit$fitted.values, main = "Heteroskedastic Residuals", xlab = "Predicted Values", ylab = "Residuals")
abline(h=0, col="red")

#residuals vs fitted plot
plot(lm.fit, which = 1)

#checking for serial correlation
dwtest(lm.fit)

```

## Descriptive Analytics 
We can see from the qqplot that the data deviates from the qqline. It is somewhat following, but deviates around -0.5 and 0, and again, from 1 and onwards.As the Standardized residuals increase, the deviation becomes more apparent. Looking at the histogram, it seems that it skews to the left. Based on these two plots, I would conclude that the residuals are not normally distributed.

The "Heteroskedastic Residuals" plot clearly shows heteroskedasticity is present in our data. When plotting Residuals vs Fitted, it clearly is not homoskedastic, and the wave indicates a cyclical pattern, which makes sense since we have time series data.

Now, it seems clear that our OLS assumptions do not hold, and we have a problem with heteroskedasticity -- most likely related to the fact that we have time series data. We must check for serial correlation. We use the Durbin Watson test here, and find that the DW statistic is 0.58559 and the p value is much smaller than 0.05. Since our DW stat is close to 0, that means we have extreme positive serial correlation. We must correct by lagging. 

## Define an initial set of predictors

Our initial set of predictors will include: Date, end of the month for every month from 2018 to November 2024; Median Sale Price, New Construction Sales, and Mean SFR value (Single Family Residence). We will focus on building our model using data from the New York, New York region.

## OLS or Logistic Regression

Since we have concluded that our data suffers from serial correlation, we must transform our variables and lag the data. Therefore, we will use logistic regression to build our model.

```{r lagging to correct for serial correlation}

#create lagged variables

ny_housing_data_clean <- ny_housing_data_clean %>%
  arrange(Date) %>%
  mutate(
    Date.L6 = Date %m+% months(-6),  # Lag by 6 months
    Date.L12 = Date %m+% months(-12) # Lag by 12 months
  )

#regression with lagged variables
fit.lag <- lm(median_sale_price ~ Date + Date.L6 + Date.L12 + new_construction_sales + mean_sfr_value, data = ny_housing_data_clean)

summary(fit.lag)

```
## Transformation in Preparation for a Regression

It seems that lagging by 6 months is not significant, but a 12 month lag (1 year) is significant. We should check if the serial correlation problem is corrected.

```{r check for serial correlation correction}

plot(ny_housing_data_clean$Date[13:nrow(ny_housing_data_clean)],
     fit.lag$residuals[13:length(fit.lag$residuals)],
     xlab = "Date",
     ylab = "Residuals")
abline(0,0, col="red")

dwtest(fit.lag)
```
## Data Preparation

From preliminary inspection of the plot, it does not seem that the serial correlation problem has been resolved. The DW test also still confirms that we have positive serial correlation, as it is closer to 0-1 than it is to 2.

## Modeling

## Analysis

## Conclusion